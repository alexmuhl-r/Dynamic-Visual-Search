# Dynamic Visual Search
Dynamic visual search tasks in Python and SR Research's Experiment Builder by Alex Muhl-Richardson and Hayward Godwin.

Please note: all of these tasks require SR Research's Experiment Builder and an Eyelink eye tracker to run (tested on Eyelink 1000 and 1000 Plus). However, there is no reason in principle why the core elements of these tasks that exist as Python code could not be adapted to other software and hardware configurations.

In all cases, use of the experiments is simple:

1. Download the entire contents of your chosen branch
2. Open 'graph.ebd' in SR Research's Experiment Builder and specify desired properties (refresh rate, dummy mode, etc.)
3. Hit the run button and the experiment will begin by asking for a number of task parameters, set these according to the branch readme/desried experimental conditions

### Branches

The branches of this respository include different specific task configurations that have been used in our experiments:

#### Stream 1

- **[exp1/2-control](https://github.com/alexmuhl-r/dynamic-visual-search/tree/exp1/2-control)** was used in the control conditions in Experiments 1 and 2 in our JEP: Applied paper (see below)

- **[exp1-random](https://github.com/alexmuhl-r/dynamic-visual-search/tree/exp1-random)** was used in the random condition of Experiment 1 in our JEP: Applied paper

- **[exp2-random-sequence](https://github.com/alexmuhl-r/dynamic-visual-search/tree/exp2-random-sequence)** was used in the random sequence of Experiment 2 in our JEP: Applied paper

- **[exp3-low-prevalence](https://github.com/alexmuhl-r/dynamic-visual-search/tree/exp3-low-prevalence)** was used in Experiment 3 in our JEP: Applied paper

#### Stream 2

- **[colour-digit-dual-task](https://github.com/alexmuhl-r/dynamic-visual-search/tree/colour-digit-dual-task)** was used in our Applied Cognitive Psychology paper

#### Stream 3

- **[high-prevalence](https://github.com/alexmuhl-r/dynamic-visual-search/tree/high-prevalence)** was used in our preprint on PsyArXiv

### For more information about these tasks and how they have been used, please see our published papers, preprints and project page on the Open Science Framework:

- Muhl-Richardson, A., Godwin, H. J., Garner, M., Hadwin, J. A., Liversedge, S. P & Donnelly, N. (2018). Individual Differences in Search and Monitoring for Color Targets in Dynamic Visual Displays. Journal of Experimental Psychology: Applied, 24(4), 564-577. http://dx.doi.org/10.1037/xap0000155

- Muhl-Richardson, A., Cornes, K., Godwin, H. J., Garner, M., Hadwin, J. A., Liversedge, S. P. & Donnelly, N. (2018). Searching for Two Categories of Target in Dynamic Visual Displays Impairs Monitoring Ability. Applied Cognitive Psychology, 32(4), 440-449. https://doi.org/10.1002/acp.3416

- Muhl‚ÄêRichardson, A., Godwin, H. J., Garner, M., Hadwin, J. A., Liversedge, S. P & Donnelly, N. (2019, May 23).
Improving dynamic visual search via transcranial direct current stimulation and working memory training. 
https://doi.org/10.31234/osf.io/kyxb8

- Muhl-Richardson, A., Godwin, H. J., Garner, M., Hadwin, J. A., Liversedge, S. P., & Donnelly, N. (2019). Searching and Monitoring Dynamically Changing Visual Displays. https://osf.io/ahufd/
